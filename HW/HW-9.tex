\documentclass[utf8]{article}
% \usepackage{ctex}
% \usepackage{circuitikz}
% \usepackage{tikz}
% \usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{pdfpages}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
% math font
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{inputenc}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{physics}

\theoremstyle{definition}% default
\newtheorem{question}{Question} %
\theoremstyle{plain}% 
\newtheorem{answer}{Answer} %

\input{math_cmds.tex}

\title{Problem Set 9}
\author{ FHYQ-Dong, Class **********, Student ID: ********** }
\date{\today}

\geometry{a4paper, scale=0.8}
\setlength{\columnsep}{20pt}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}
\lhead{Problem Set 9}
\rhead{ FHYQ-Dong }
\cfoot{---~\thepage~---}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=black,      
    urlcolor=black,
    citecolor=black,
}


\begin{document}

\maketitle
\thispagestyle{fancy}

\begin{question}
    Consider a PDF that is positive only within an interval $[a, b]$ and is symmetric around the mean $(a + b)/2$. Let $X$ and $Y$ be independent random variables that both have this PDF. Suppose that you have calculated the PDF of $X + Y$. How can you easily obtain the PDF of $X - Y$?
\end{question}
\begin{answer}
Let $f_{X}(x)$ denote the PDF of $X$. ($f_{Y}(y)$ is the same.) Let $W = X + Y$ and $Z = X - Y$. Then the PDF of $W$ and $Z$ is
\begin{align}
    \label{eq:pdf-w}
    f_{W}(w) &= \int_{-\infty}^{+\infty} f_{X}(x) f_{Y}(w - x) \dd{x} \\ 
    \label{eq:pdf-z1}
    f_{Z}(z) &= \int_{-\infty}^{+\infty} f_{X}(x) f_{Y}(z + x) \dd{x}
\end{align}
Given the symmetry of $f_{Y}(y)$, if we exchange $z + x$ with $a + b - z - x$, the result remains unchanged, i.e.
\begin{equation}
    \label{eq:pdf-z2}
    f_{Z}(z) = \int_{-\infty}^{+\infty} f_{X}(x) f_{Y}\qty(a + b - z - x) \dd{x}
\end{equation}
Compare Eq.(\ref{eq:pdf-z2}) with Eq.(\ref{eq:pdf-w}), we can observe that
\begin{equation}
    f_{Z}(z) = f_{W}(a + b - z)
\end{equation}
which is an easy way to obtain the PDF of $X - Y$ from the PDF of $X + Y$.
\end{answer}

\begin{question}
    Consider four random variables, $W$, $X$, $Y$, $Z$, with
    \begin{equation}
    \begin{aligned}
        \E[W] = \E[X] = \E[Y] = \E[Z] = 0 \\
        \var(W) = \var(X) = \var(Y) = \var(Z) = 1 
    \end{aligned}
    \end{equation}
    and assume that $W$ ,$X$ ,$Y$, $Z$ are pairwise uncorrelated. Find the correlation coefficients $\rho(R, S)$ and $\rho(R, T)$, where $R = W + X$, $S = X + Y$, and $T = Y + Z$.
\end{question}
\begin{answer}
    According to the linearity of expectation and given that $W$, $X$, $Y$ and $Z$ are pairwise uncorrelated
    \begin{equation}
    \begin{aligned}
        \E[R] = \E[S] = \E[T] = 0 \\ 
        \var(R) = \var(S) = \var(T) = 2 
    \end{aligned}
    \end{equation}
    According to the bilinearity of covariance
    \begin{equation}
    \begin{aligned}
        \cov(R, S) = \cov(W + X, X + Y) = \cov(W, X) + \cov(W, Y) + \cov(X, X) + \cov(X, Y) = 1 \\
        \cov(R, T) = \cov(W + X, Y + Z) = \cov(W, Y) + \cov(W, Z) + \cov(X, Y) + \cov(X, Z) = 0
    \end{aligned}
    \end{equation}
    Therefore, the correlation coefficients are
    \begin{equation}
    \begin{aligned}
        \rho(R, S) &= \frac{\cov(R, S)}{\sqrt{\var(R) \var(S)}} = \frac{1}{2} \\
        \rho(R, T) &= \frac{\cov(R, T)}{\sqrt{\var(R) \var(T)}} = 0
    \end{aligned}
    \end{equation}
\end{answer}

\begin{question}
    Pat and Nat are dating, and all of their dates are scheduled to start at 9 p.m. Nat always arrives promptly at 9 p.m. Pat is highly disorganized and arrives at a time that is uniformly distributed between 8 p.m. and 10 p.m. Let $X$ be the time in hours between 8 p.m. and the time when Pat arrives. If Pat arrives before 9 p.m., their date will last exactly 3 hours. If Pat arrives after 9 p.m., their date will last for a time that is uniformly distributed between 0 and $3 - X$ hours. The date starts at the time they meet. Nat gets irritated when Pat is late and will end the relationship after the second date on which Pat is late by more than 45 minutes. All dates are independent of any other dates.
    \begin{enumerate}[label=(\alph*)]
        \item What is the expected number of hours Nat waits for Pat to arrive? 
        \item What is the expected duration of any particular date?
        \item What is the expected number of dates they will have before breaking up?
    \end{enumerate}
\end{question}
\begin{answer} ~ 
    \begin{enumerate}[label=(\alph*)]
        \item There's a 50\% chance for Pat to arrive before 9 p.m. under which circumstances Nat will not need to wait. For the other 50\% chance, Pat will arrive at a time uniformly distributed between 9 p.m. and 10 p.m. Therefore, the expected waiting time is
        \begin{equation}
            \E[T] = \int_{0}^{1} \frac{1}{2} \cdot 0 \dd{x} + \int_{1}^{2} \frac{x}{2} \dd{x} = \frac{1}{4}
        \end{equation}
        \item There's a 50\% chance for Pat to arrive before 9 p.m. under which circumstances the date will lasts for 3 hours. For the other 50\% chance, Pat will arrive at a time uniformly distributed between 9 p.m. and 10 p.m. Given that Pat arrives after 9 p.m. and given that Path arrives at the time $X$, let $Y$ be the duration of the date. The expected duration of the date given $X = x, x > 9$ is
        \begin{equation}
            \E[Y \mid X = x] = \int_{0}^{3-x} \frac{y}{3 - x} \dd{y} = \frac{3 - x}{2}
        \end{equation}
        Therefore according to the total expectation theorem, the expectated duration of a particular date is
        \begin{equation}
            \E[Y] = \frac{3}{2} + \int_{1}^{2} \frac{1}{2} \cdot \frac{3 - x}{2} \dd{x} = \frac{15}{8}
        \end{equation}
        \item For a particular date, thers's $p = 1/8$ probability that Pat is late by more than 45 minutes. Let $N$  be the number of dates before breaking up. Then the expectated number of dates between the two dates on which Pat is late by more than 45 minutes is 8 (geometric distribution). Therefore, the expected number of dates before breaking up is
        \begin{equation}
            \E[N] = 2 \times 8 = 16
        \end{equation}
    \end{enumerate}
\end{answer}

\begin{question}
    An urn contains $a$ white and $b$ black balls. After a ball is drawn, it is returned to the urn if it is white; but if it is black, it is replaced by a white ball from another urn. Let $M_n$ denote the expected number of white balls in the urn after the foregoing operation has been repeated $n$ times.
    \begin{enumerate}[label=(\alph*)]
        \item \label{q:4.a} Derive the recursive equation
        \begin{equation}
            M_{n+1} = \qty(1 - \frac{1}{a + b}) M_n + 1
        \end{equation}
        \item Use part \ref{q:4.a} to prove that
        \begin{equation}
            M_n = a + b - b \qty(1 - \frac{1}{a + b})^n
        \end{equation}
        \item What is the probability that the $(n + 1)$-th ball drawn is white in terms of $M_n$?
    \end{enumerate}
\end{question}
\begin{answer} ~ 
    \begin{enumerate}[label=(\alph*)]
        \item Divide $M_{n+1}$ using the result of the $n+1$-th draw
        \begin{equation}
        \begin{aligned}
            \label{eq:Mn-recusion}
            M_{n+1} &= \E[M_{n+1} \mid \text{white}] \cdot \mathbf{P}(\text{white}) + \E[M_{n+1} \mid \text{black}] \cdot \mathbf{P}(\text{black}) \\ 
            &= M_n \cdot \frac{M_n}{a + b} + \qty(M_n + 1) \cdot \qty(1 - \frac{M_n}{a + b}) = \qty(1 - \frac{1}{a + b}) M_n + 1
        \end{aligned}
        \end{equation}
        \item From Eq.(\ref{eq:Mn-recusion}), we assume that there exists $x$ such that
        \begin{equation}
            \label{eq:Mn-assume}
            (M_{n+1} + x) = \qty(1 - \frac{1}{a + b}) (M_n + x)
        \end{equation}
        Compare Eq.(\ref{eq:Mn-assume}) with Eq.(\ref{eq:Mn-recusion}), we can find out that $x = -(a + b)$. Therefore 
        \begin{equation}
            \frac{M_{n+1} - (a + b)}{M_n - (a + b)} = 1 - \frac{1}{a + b} \quad \Rightarrow \quad M_n - (a + b) = (M_0 - (a + b)) \cdot \qty(1 - \frac{1}{a + b})^n
        \end{equation}
        Given that $M_0 = a$, we have
        \begin{equation}
            M_n = a + b - b \qty(1 - \frac{1}{a + b})^n
        \end{equation}
        \item \begin{equation}
            \mathbf{P}((n+1)\text{-th ball is white}) = \frac{M_n}{a + b}
        \end{equation}
    \end{enumerate}
\end{answer}

\begin{question}
    The joint distribution of $X_1$ and $X_2$ follows bivariate Gaussian distribution. The joint PDF is
    \begin{equation}
        f_{X_1, X_2}(x_1, x_2) = \frac{1}{2\pi \sigma_1\sigma_2 \sqrt{1 - \rho^2}} \exp\qty(-\frac{1}{2(1 - \rho^2)} \qty(\frac{(x_1-\mu_1)^2}{\sigma_1^2} - \frac{2\rho(x_1-\mu_1)(x_2-\mu_2)}{\sigma_1\sigma_2} + \frac{(x_2-\mu_2)^2}{\sigma_2^2}))
    \end{equation}
    where $\rho$ is the correlation coefficient of $X_1$ and $X_2$.
    \begin{enumerate}[label=(\alph*)]
        \item Find $f_{X_2}(x_2)$, $\E[X_2]$ and $\var(X_2)$. Is $f_{X_2}(x_2)$ Gaussian?
        \item Find $f_{X_2 \mid X_1}(x_2 \mid x_1)$, $\E[X_2 \mid X_1]$ and $\var(X_2 \mid X_1)$. Is $f_{X_2 \mid X_1}(x_2 \mid x_1)$ Gaussian?
    \end{enumerate}
\end{question}
\begin{answer} ~ 
    \begin{enumerate}[label=(\alph*)]
        \item Given the equation
        \begin{equation}
            \int_{-\infty}^{+\infty} \exp\qty(-a x^2 \pm b x) \dd{x} = \sqrt{\frac{\pi}{a}} \exp\qty(\frac{b^2}{4a})
        \end{equation}
        we can find out that
        \begin{equation}
        \begin{aligned}
            &f_{X_2}(x_2) = \int_{-\infty}^{+\infty} f_{X_1, X_2}(x_1, x_2) \dd{x_1} \\
            &= \frac{1}{2\pi \sigma_1\sigma_2 \sqrt{1 - \rho^2}} \exp\qty(-\frac{(x_2 - \mu_2)^2}{2(1 - \rho^2)\sigma_2^2}) \int_{-\infty}^{+\infty} \exp\qty(-\frac{(x_1 - \mu_1)^2}{2(1 - \rho^2)\sigma_1^2} + \frac{\rho (x_1 - \mu_1)(x_2 - \mu_2)}{(1 - \rho^2)\sigma_1\sigma_2}) \dd{x_1} \\ 
            &= \frac{1}{2\pi \sigma_1\sigma_2 \sqrt{1 - \rho^2}} \exp\qty(-\frac{(x_2 - \mu_2)^2}{2(1 - \rho^2)\sigma_2^2}) \cdot \sqrt{2\pi (1 - \rho^2) \sigma_1^2} \exp\qty(\frac{\rho^2 (x_2 - \mu_2)^2}{2(1 - \rho^2)\sigma_2^2}) \\ 
            &= \frac{1}{\sqrt{2\pi} \sigma_2} \exp\qty(-\frac{(x_2 - \mu_2)^2}{2\sigma_2^2}) 
        \end{aligned}
        \end{equation}
        which is a Gaussian distribution with mean $\mu_2$ and variance $\sigma_2^2$.
        \item Given the symmetry of the joint PDF, the PDF of $X_1$ is the same as $X_2$
        \begin{equation}
            f_{X_1}(x_1) = \frac{1}{\sqrt{2\pi} \sigma_1} \exp\qty(-\frac{(x_1 - \mu_1)^2}{2\sigma_1^2})
        \end{equation}
        And the conditional PDF $f_{X_2 \mid X_1}(x_2 \mid x_1)$ is
        \begin{equation}
        \begin{aligned}
            &f_{X_2 \mid X_1}(x_2 \mid x_1) = \frac{f_{X_1, X_2}(x_1, x_2)}{f_{X_1}(x_1)} \\ 
            &= \frac{1}{\sqrt{2\pi} \sigma_2\sqrt{1 - \rho^2}} \exp\qty(-\frac{1}{2(1 - \rho^2)} \qty(\frac{\rho^2 (x_1 - \mu_1)^2}{\sigma_1^2} - \frac{2\rho(x_1-\mu_1)(x_2-\mu_2)}{\sigma_1\sigma_2} + \frac{(x_2-\mu_2)^2}{\sigma_2^2})) \\
            &= \frac{1}{\sqrt{2\pi} \sigma_2\sqrt{1 - \rho^2}} \exp\qty(-\frac{1}{2(1 - \rho^2)} \qty(\frac{\rho (x_1 - \mu_1)}{\sigma_1} - \frac{x_2 - \mu_2}{\sigma_2})^2) \\ 
            &= \frac{1}{\sqrt{2\pi} \sigma_2\sqrt{1 - \rho^2}} \exp\qty(-\frac{\qty(x_2 - \mu_2 - \rho \frac{\sigma_2}{\sigma_1} (x_1 - \mu_1))^2}{2(1 - \rho^2)\sigma_2^2}) 
        \end{aligned}
        \end{equation}
        which is also a Gaussian distribution with mean $\mu_2 + \rho \frac{\sigma_2}{\sigma_1} (x_1 - \mu_1)$ and variance $(1 - \rho^2)\sigma_2^2$.
    \end{enumerate}
\end{answer}

\end{document}
